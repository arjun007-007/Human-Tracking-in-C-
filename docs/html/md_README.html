<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Human Obstacle &amp; Tracking: README</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Human Obstacle &amp; Tracking
   &#160;<span id="projectnumber">1</span>
   </div>
   <div id="projectbrief">A C++ library to detect human obstacles in video stream and output distance of obstacle with respect to the robot reference frame</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">README </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><img src="https://github.com/MayankD409/Human_Tracking_CPP/actions/workflows/run-unit-test-and-upload-codecov.yml/badge.svg" alt="CICD Workflow status" style="pointer-events: none;" class="inline"/> <a href="https://codecov.io/gh/MayankD409/Human_Tracking_CPP"><img src="https://codecov.io/gh/MayankD409/Human_Tracking_CPP/graph/badge.svg?token=5CKBQ8V2WE" alt="codecov" style="pointer-events: none;" class="inline"/></a> [<img src="https://img.shields.io/badge/license-MIT-blue.svg" alt="License" style="pointer-events: none;" class="inline"/>](LICENSE)</p>
<p>This repository consists of deliverables for the Midterm Project for,</p><ul>
<li>Lowell Lobo (120095719)</li>
<li>Kautilya Chappidi (120380204)</li>
<li>Mayank Deshpande (120387333)</li>
</ul>
<h1><a class="anchor" id="autotoc_md0"></a>
Project Overview</h1>
<p>Perception is essential for object detection, environmental awareness, path planning and control; through perception, a system can truly be considered autonomous. Acme requires the development of a perception component in its autonomous car system, and a human obstacle detection and tracking module needs to be built. The aim is to build a perception module to detect human objects and track their location directly into the robot reference frame. The location will first be found with respect to the camera's reference frame and then using a transformation, the location with respect to the robot reference frame will be found. The module is built such that, the system that implements it will consists of a camera mounted on a car that will keep track of human motion within the cameraâ€™s field of view. But the module will be unable to handle occlusion cases.</p>
<h2><a class="anchor" id="autotoc_md1"></a>
Assumption</h2>
<p>The camera used for perception will be placed on the top of the car. The camera reference frame is taken such that the z-axis is pointing out of the lens, the x-axis is to the right, and the y-axis is pointing downward. The robot reference frame is at the centre of mass where the z-axis points upward, and the x-axis is to the right, and the y-axis points straight ahead. We assume the camera is monocular, and the user must input most of the configuration information</p>
<h2><a class="anchor" id="autotoc_md2"></a>
Features</h2>
<ul>
<li>Detection of human obstacles and tracking using monocular camera</li>
<li>Location of human obstacle with respect to robot reference frame</li>
<li>DisplayClass to implement and test the module</li>
</ul>
<h2><a class="anchor" id="autotoc_md3"></a>
Deliverables</h2>
<ul>
<li>C++ library/API for human obstacle and tracking</li>
<li>GitHub Repository with CI and CodeCov</li>
<li>UML and Dependency Diagrams</li>
<li>Doxygen Documentation</li>
</ul>
<h2><a class="anchor" id="autotoc_md4"></a>
Constraints</h2>
<p>The module uses a monocular camera and is unable to handle occlusions. Also, the monocular camera cannot perform precise depth calculation and thus would require a deep learning model for accurate estimation. The runtime fps and memory management depend on the physical constraints of the system.</p>
<h1><a class="anchor" id="autotoc_md5"></a>
Personnel</h1>
<p>Kautilya Chappiddi:- <br  />
 Graduate Student in Enginnering - Robotics at University of Maryland, College Park</p>
<p>Lowell Lobo:- <br  />
 Graduate Student in Enginnering - Robotics at University of Maryland, College Park</p>
<p>Mayank Deshpande:- <br  />
 Graduate Student in Enginnering - Robotics at University of Maryland, College Park</p>
<h1><a class="anchor" id="autotoc_md6"></a>
Process</h1>
<p>The project development will be executed using pair programming concepts. For all specific tasks, driver and navigator roles will be swapped. The project will follow AIP concepts and be performed using Pair Programming. The module works such that a video is fed into the system using the monocular camera. The program then converts the video stream into image frames and performs human obstacle detection. Once obstacles are found in the image frame, unique IDs are assigned to the objects, which will hold the calculated current location with respect to the robot reference frame. The process is repeated over time for tracking of obstacle movement. Testing of components is performed using GoogleTest, and system testing will be performed every iteration for overall functionality verification.</p>
<h1><a class="anchor" id="autotoc_md7"></a>
AIP Methodology</h1>
<p>The project was implemented using Agile Iterative Process (AIP) along with pair programming and a test-driven development approach. Product backlog, iteration backlogs for each phase and work log have been created. Each iteration started with a meeting to discuss the agenda and ends with a sprint review.</p>
<h1><a class="anchor" id="autotoc_md8"></a>
Links</h1>
<p><a href="https://docs.google.com/spreadsheets/d/17q5Q-qL-ZU2LQK8llQSjsIJ8_037MAFyNenNofpY_PI/edit#gid=0">AIP Google Sheet</a></p>
<p><a href="https://docs.google.com/document/d/1UX6oGidNdux2FeOGgIjD-ivvmi8oCiHlf1OJARla3Ro/edit">Sprint Notes</a></p>
<h1><a class="anchor" id="autotoc_md9"></a>
Dependencies</h1>
<p>The project uses the OpenCV library to read video frame, perform image processing and run inference. <br  />
 Together with OpenCV, a pretrained ResNet Caffemodel is used in the implementation.</p>
<h1><a class="anchor" id="autotoc_md10"></a>
Installing Dependencies</h1>
<p>OpenCV can be installed as follows, </p><div class="fragment"><div class="line">sudo apt install libopencv-dev</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md11"></a>
API Information</h1>
<p>The API contains three libraries, <br  />
</p>
<h3><a class="anchor" id="autotoc_md12"></a>
1 - detection library</h3>
<p><br  />
 The library is used to initialise and access the Video Stream and runs face detection to find human obstacles in the image frame.</p>
<p>It consists of two method and a constructor:- <br  />
</p><ul>
<li>initVideoStream()</li>
<li>detectFaces() <br  />
 &ndash; Constructor <br  />
 The constructor initialises the detection model in OpenCV using the readNet() method <br  />
 <br  />
 &ndash; initVideoStream() <br  />
 The VideoStream is initialised to constantly read image frames from the camera setup. <br  />
 <br  />
 &ndash; detectFaces() Uses the model that was initialised to detect faces in the image frame and return bounding boxes above a confidence level in the format cv::Rect <br  />
 <br  />
</li>
</ul>
<h3><a class="anchor" id="autotoc_md13"></a>
2 - tracking library</h3>
<p><br  />
 The library is used to find the (x, y, z) coordinates of the obstacle with respect to the robot reference frame. The library also tracks the motion of obstacles by assigning a unique ID to each object.</p>
<p>It consists of four methods:- <br  />
</p><ul>
<li>assignIDAndTrack()</li>
<li>distFromCamera()</li>
<li>distFromCar()</li>
<li>findDepth() <br  />
 &ndash; assignIDAndTrack() <br  />
 This method receives the bounding boxes and returns the bounding boxes with a unique ID assigned to them. If there are no IDs assigned, the algorithm assigns IDs to each detection. If the number of detections are equal to the number of IDs assigned, the algorithm computes and assigns IDs based on minimum Euclidean distance between detection. This consists the tracking feature. If the number of detections are greater than the number of assigned IDs, then the algorithm reassigns the correct IDs to the corresponding detection and assigns new IDs to the new detections. If the number of detections are lesser than the number of assigned IDs, if the detection is near the edge and the minimum Euclidean distance is greater than a specific value then the ID is deallocated. But if the detection is lost in the center of the frame, false detection is assumed, and the detection with ID is retained. If all conditions above are not met, the ID is reassigned. <br  />
 <br  />
 &ndash; distFromCamera() <br  />
 This method takes in the the IDs mapped to the bounding boxes and returns the (x, y, z) pixel distance of the obstacle from the camera reference frame using geometry. <br  />
 <br  />
 &ndash; distFromCar() <br  />
 This method takes in (x, y, z) pixel distance of the obstacle from the camera reference frame and returns the (x, y, z) distance of the obstacle from the car reference frame in inches. Rotation, Translation and geometry are used to find the distance in inches. <br  />
 <br  />
 &ndash; findDepth() <br  />
 This method takes in the ID and returns the z distance in inches. The z distance is found analytically by using sampling and linearising the conversion function.</li>
</ul>
<h1><a class="anchor" id="autotoc_md14"></a>
Running the Application</h1>
<h2><a class="anchor" id="autotoc_md15"></a>
Build via command-line</h2>
<div class="fragment"><div class="line"># Configure the project and generate a native build system:</div>
<div class="line">  # Must re-run this command whenever any CMakeLists.txt file has been changed.</div>
<div class="line">  cmake -S ./ -B build/</div>
<div class="line"> </div>
<div class="line"># Compile and build the project:</div>
<div class="line">  # rebuild only files that are modified since the last build</div>
<div class="line">  cmake --build build/</div>
<div class="line">  # or rebuild everything from scracth</div>
<div class="line">  cmake --build build/ --clean-first</div>
<div class="line">  # to see verbose output, do:</div>
<div class="line">  cmake --build build/ --verbose</div>
<div class="line"> </div>
<div class="line"># Alternate method to build the project:</div>
<div class="line">  # build compile_commands.json from scratch</div>
<div class="line">  bear -- cmake --build build/ --clean-first</div>
<div class="line">  # or, update the existing compile_commands.json</div>
<div class="line">  bear --append -- cmake --build build/</div>
<div class="line"> </div>
<div class="line"># Run program for testing the actual application:</div>
<div class="line">  ./build/app/human-tracker</div>
<div class="line"> </div>
<div class="line"># Clean</div>
<div class="line">  cmake --build build/ --target clean</div>
<div class="line"># Clean and start over:</div>
<div class="line">  rm -rf build/</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md16"></a>
Running Unit Tests</h2>
<div class="fragment"><div class="line"># Run tests:</div>
<div class="line">  cd build/; ctest; cd -</div>
<div class="line">  # or if you have newer cmake</div>
<div class="line">  ctest --test-dir build/</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md17"></a>
Generate Documentation</h2>
<h3><a class="anchor" id="autotoc_md18"></a>
Method 1</h3>
<div class="fragment"><div class="line"># Download doxygen</div>
<div class="line">  sudo apt-get install doxygen</div>
<div class="line"># Build documentation</div>
<div class="line">  doxygen dconfig</div>
</div><!-- fragment --> <h3><a class="anchor" id="autotoc_md19"></a>
Method 2</h3>
<div class="fragment"><div class="line"># Build docs:</div>
<div class="line">  cmake --build build/ --target docs</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md20"></a>
View Documentation</h3>
<div class="fragment"><div class="line"># open a web browser to browse the doc</div>
<div class="line">  open docs/html/index.html</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md21"></a>
Building for code coverage</h1>
<div class="fragment"><div class="line"># if you don&#39;t have gcovr or lcov installed, do:</div>
<div class="line">  sudo apt-get install gcovr lcov</div>
<div class="line"># Set the build type to Debug and WANT_COVERAGE=ON</div>
<div class="line">  cmake -D WANT_COVERAGE=ON -D CMAKE_BUILD_TYPE=Debug -S ./ -B build/</div>
<div class="line"># Now, do a clean compile, run unit test, and generate the covereage report</div>
<div class="line">  cmake --build build/ --clean-first --target all test_coverage</div>
<div class="line"># open a web browser to browse the test coverage report</div>
<div class="line">  open build/test_coverage/index.html</div>
<div class="line"> </div>
<div class="line">This generates a index.html page in the build/test_coverage sub-directory that can be viewed locally in a web browser.</div>
</div><!-- fragment --><p>You can also get code coverage report for the <em>human-tracker</em> target, instead of unit test. Repeat the previous 2 steps but with the <em>app_coverage</em> target:</p>
<div class="fragment"><div class="line"># Now, do another clean compile, run shell-app, and generate its covereage report</div>
<div class="line">  cmake --build build/ --clean-first --target all app_coverage</div>
<div class="line"># open a web browser to browse the test coverage report</div>
<div class="line">  open build/app_coverage/index.html</div>
<div class="line"> </div>
<div class="line">This generates a index.html page in the build/app_coverage sub-directory that can be viewed locally in a web browser.</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md22"></a>
CodeCov Outputs</h1>
<p>Unit tests were chosen to try to meet all run condition cases, but some were still missed. Thus coverage report is reduced in <a class="el" href="classTrackingClass.html" title="A class for Tracking Subjects on the Frame.">TrackingClass</a>. <br  />
 <a class="el" href="classDetectionClass.html" title="A class for performing face detection using a deep learning model.">DetectionClass</a> requires to initialise a VideoStream, which is not possible in GitHub Actions.</p>
<h2><a class="anchor" id="autotoc_md23"></a>
compile_commands.json Errors</h2>
<p>In case of error regarding the generation of compile_commands.json file, Delete the compile_commands.json file and run the following </p><div class="fragment"><div class="line">bear -- cmake --build build/ --clean-first</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
